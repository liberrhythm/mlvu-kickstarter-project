{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant imports\n",
    "\n",
    "# base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# data prep\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from scipy import stats\n",
    "\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# import metrics\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, average_precision_score\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, log_loss, precision_recall_curve\n",
    "# !pip install seaborn\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# uncomment !pip install commands if you get an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import feature data - make sure csv files are in the same directory\n",
    "x_train = pd.read_csv(\"./x_train.csv\")\n",
    "x_val = pd.read_csv(\"./x_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import state data => no header, so you have to specify header=None\n",
    "y_name = [\"state\"]\n",
    "y_train = pd.read_csv(\"./y_train.csv\", names=y_name, header=None)\n",
    "y_val = pd.read_csv(\"./y_val.csv\", names=y_name, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 1-column dataframe into series\n",
    "y_train = y_train['state']\n",
    "y_val = y_val['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "from sklearn import svm\n",
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object (using linearsvc to handle large number of instances better)\n",
    "clf = svm.LinearSVC(C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6795457400567825"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_train, y_train)\n",
    "#Predict Output\n",
    "# predicted= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions and probabilities\n",
    "predictions = clf.predict(x_val)\n",
    "probabilities = clf.predict_proba(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance of each feature\n",
    "list(zip(x_train, clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_predictions = clf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation accuracy\n",
    "print (\"Training Accuracy: \", accuracy_score(y_train, training_predictions))\n",
    "print (\"Validation Accuracy: \", accuracy_score(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation balanced accuracy\n",
    "print (\"Training Balanced Accuracy: \", balanced_accuracy_score(y_train, training_predictions))\n",
    "print (\"Validation Balanced Accuracy: \", balanced_accuracy_score(y_val, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix basic stats\n",
    "cm = confusion_matrix(y_val, predictions)\n",
    "print(\"Confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better confusion matrix depiction\n",
    "pd.crosstab(y_val, predictions, rownames=['Actual Status'], colnames=['Predicted Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best confusion matrix depiction using seaborn heatmap\n",
    "class_names = y_val.unique()\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "fig = plt.figure()\n",
    "heatmap = sn.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel('Predicted status')\n",
    "plt.ylabel('Actual status')\n",
    "plt.title('Confusion Matrix for Random Forest Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report with relevant statistics\n",
    "cr = classification_report(y_val, predictions)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Log loss: \", log_loss(y_val, probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = zip(*probabilities)\n",
    "plt.scatter(x,y)\n",
    "plt.title(\"Probability Matrix Plot\")\n",
    "plt.xlabel(\"Probability of failure\")\n",
    "plt.ylabel(\"Probability of success\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities for the positive class (second column in probabilities)\n",
    "positive_probabilities = probabilities[:,1]\n",
    "# is over 0.5 - which is the standard for a no-skill model\n",
    "print(\"ROC_AUC score: \", roc_auc_score(y_val.cat.codes, positive_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our dataset is balanced - this one is better\n",
    "# plot ROC curve\n",
    "# https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "fpr, tpr, thresholds = roc_curve(y_val.cat.codes, positive_probabilities)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_val.cat.codes, positive_probabilities)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
