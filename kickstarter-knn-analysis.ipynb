{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant imports\n",
    "\n",
    "# base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# data prep\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from scipy import stats\n",
    "\n",
    "# nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# import metrics\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, average_precision_score\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, log_loss, precision_recall_curve\n",
    "# !pip install seaborn\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# uncomment !pip install commands if you get an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import feature data - make sure csv files are in the same directory\n",
    "# x_train = pd.read_csv(\"./x_train.csv\")\n",
    "# x_val = pd.read_csv(\"./x_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val = pd.read_csv(\"./x_train_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import state data => no header, so you have to specify header=None\n",
    "y_name = [\"state\"]\n",
    "# y_train = pd.read_csv(\"./y_train.csv\", names=y_name, header=None)\n",
    "# y_val = pd.read_csv(\"./y_val.csv\", names=y_name, header=None)\n",
    "y_train_val = pd.read_csv(\"./y_train_val.csv\", names=y_name, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train['state'] = y_train['state'].astype('category')\n",
    "# y_val['state'] = y_val['state'].astype('category')\n",
    "y_train_val['state'] = y_train_val['state'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([x_train,y_train],axis=1)\n",
    "# val = pd.concat([x_val,y_val],axis=1)\n",
    "train_val = pd.concat([x_train_val,y_train_val],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train.isnull().values.any())\n",
    "# print(val.isnull().values.any())\n",
    "print(train_val.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = train_val.sample(15000)\n",
    "df2 = train_val.sample(25000)\n",
    "df3 = train_val.sample(35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1['state'] # define target variable\n",
    "x = df1.drop('state', axis=1)  \n",
    "x_train_1, x_val_1, y_train_1, y_val_1 = train_test_split(x, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['state'] # define target variable\n",
    "x = df2.drop('state', axis=1)  \n",
    "x_train_2, x_val_2, y_train_2, y_val_2 = train_test_split(x, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df3['state'] # define target variable\n",
    "x = df3.drop('state', axis=1)  \n",
    "x_train_3, x_val_3, y_train_3, y_val_3 = train_test_split(x, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 1-column dataframe into series\n",
    "# y_train = y_train['state']\n",
    "# y_val = y_val['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start of KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=30,weights='uniform',algorithm='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(x_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(x_val_3)\n",
    "probabilities = classifier.predict_proba(x_val_3)\n",
    "train_predictions = classifier.predict(x_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Training Accuracy: \", accuracy_score(y_train_3, train_predictions))\n",
    "print (\"Validation Accuracy: \", accuracy_score(y_val_3, predictions))\n",
    "# training and validation balanced accuracy\n",
    "print (\"Training Balanced Accuracy: \", balanced_accuracy_score(y_train_3, train_predictions))\n",
    "print (\"Validation Balanced Accuracy: \", balanced_accuracy_score(y_val_3, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix basic stats\n",
    "# cm = confusion_matrix(y_val_2, predictions)\n",
    "# print(\"Confusion matrix\")\n",
    "# print(cm)\n",
    "# better confusion matrix depiction\n",
    "# pd.crosstab(y_val_2, predictions, rownames=['Actual Status'], colnames=['Predicted Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best confusion matrix depiction using seaborn heatmap\n",
    "class_names = y_val_3.unique()\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "fig = plt.figure()\n",
    "heatmap = sn.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel('Predicted status')\n",
    "plt.ylabel('Actual status')\n",
    "plt.title('Confusion Matrix - kNN with k=30 and 35000 instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report with relevant statistics\n",
    "# cr = classification_report(y_val_2, predictions)\n",
    "# print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Log loss: \", log_loss(y_val_3, probabilities))\n",
    "# get probabilities for the positive class (second column in probabilities)\n",
    "positive_probabilities = probabilities[:,1]\n",
    "# is over 0.5 - which is the standard for a no-skill model\n",
    "print(\"ROC_AUC score: \", roc_auc_score(y_val_3, positive_probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our dataset is balanced - this one is better\n",
    "# plot ROC curve\n",
    "# https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "fpr, tpr, thresholds = roc_curve(y_val_3.cat.codes, positive_probabilities, pos_label=1)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.title(\"ROC Curve - kNN with k=30 and 35000 instances\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_val_3.cat.codes, positive_probabilities)\n",
    "# plot no skill\n",
    "plt.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.title(\"Precision-Recall Curve - kNN with k=30 and 35000 instances\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
